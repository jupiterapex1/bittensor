{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bittensor\n",
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp \n",
    "import time\n",
    "from loguru import logger\n",
    "from termcolor import colored\n",
    "import nest_asyncio \n",
    "nest_asyncio.apply()\n",
    "logger.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Init Bittensor** <a class=\"anchor\" id=\"Init-Bittensor\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Wallet** <a class=\"anchor\" id=\"Wallet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLoaded coldkey.pub: 0x3c9cd1679888e5660b0c8e4b8a17a1719c0cb7f05b5c624a856b421b52290515\u001b[0m\n",
      "\u001b[32mLoaded hotkey: 0x80cacfbdf7b155b39de22680a7cb14c61a8f95df702c92f5f142d25cca37c545\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# WALLET: Holds keys to run your miner and control funds.\n",
    "\n",
    "# *****\n",
    "# IMPORTANT: Store the mnemonic for **both** your hot and coldkey \n",
    "# you will need these to recover your keys if you forget your password or lose access to this machine.\n",
    "# ******\n",
    "\n",
    "# Fill in below to name your wallet and keys.\n",
    "YOUR_WALLET_NAME = 'colab'\n",
    "YOUR_HOTKEY_NAME = 'colab_hot'\n",
    "\n",
    "# Fill in below if your need to regenerate your keys.\n",
    "use_mnemonic = False # Set to true for key regeneration.\n",
    "coldkey_mnemonic = \"<to be filled>\".split(' ')\n",
    "hotkey_mnemonic = \"<to be filled>\".split(' ')\n",
    "\n",
    "# Create the wallet object.\n",
    "wallet = bittensor.Wallet(\n",
    "    path = \"~/.bittensor/wallets/\",\n",
    "    name = YOUR_WALLET_NAME,\n",
    "    hotkey = YOUR_HOTKEY_NAME\n",
    ")\n",
    "\n",
    "# Optionally regens/creates your wallet keys.\n",
    "if not wallet.has_coldkeypub:\n",
    "    if use_mnemonic:\n",
    "        wallet.regenerate_coldkey(mnemonic = coldkey_mnemonic, use_password = True)\n",
    "    else:\n",
    "        wallet.create_new_coldkey(n_words = 12, use_password = True )\n",
    "if not wallet.has_hotkey:\n",
    "    if use_mnemonic:\n",
    "        wallet.regenerate_hotkey(mnemonic = hotkey_mnemonic)\n",
    "    else:\n",
    "        wallet.create_new_hotkey(n_words = 12)\n",
    "\n",
    "# Assert before continuing\n",
    "assert wallet.has_hotkey\n",
    "assert wallet.has_coldkeypub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Config** <a class=\"anchor\" id=\"Config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to print all config items: \n",
    "# bittensor.help()\n",
    "config = bittensor.Neuron.default_config()\n",
    "config.neuron.multiprocessing = False\n",
    "config.neuron.debug = True\n",
    "config.receptor.do_backoff = False\n",
    "config.receptor.timeout = 2\n",
    "config.subtensor.network = 'kusanagi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "axon:\n",
      "  backward_processing_timeout: 5\n",
      "  external_ip: 190.119.146.134\n",
      "  external_port: 8091\n",
      "  forward_processing_timeout: 5\n",
      "  local_ip: 127.0.0.1\n",
      "  local_port: 8091\n",
      "  max_workers: 10\n",
      "  use_upnpc: false\n",
      "metagraph:\n",
      "  stale_emit_filter: -1\n",
      "neuron:\n",
      "  debug: true\n",
      "  modality: 0\n",
      "  multiprocessing: false\n",
      "receptor:\n",
      "  do_backoff: false\n",
      "  max_backoff: 100\n",
      "  pass_gradients: true\n",
      "  timeout: 2\n",
      "subtensor:\n",
      "  chain_endpoint: null\n",
      "  network: kusanagi\n",
      "wallet:\n",
      "  hotkey: colab_hot\n",
      "  name: colab\n",
      "  path: ~/.bittensor/wallets/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init bittensor components\n",
    "# NOTE: Running this call recreates bittensor objects.\n",
    "bittensor.init( with_config = config, with_wallet = wallet )\n",
    "print ( bittensor.Config.toString( bittensor.config ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Metagraph** <a class=\"anchor\" id=\"Metagraph\"></a> \n",
    "**a.k.a the chain-state as a torch object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m\n",
      "Syncing metagraph:\u001b[0m\n",
      "\u001b[32mSuccessfully connected to kusanagi endpoint: 157.230.11.1:9944\u001b[0m\n",
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Sync chain information into the metagraph\n",
    "# NOTE: expensive command.\n",
    "bittensor.metagraph.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chain is at block: 820060\n",
      "\n",
      "There are 285 neurons on the network\n",
      "\n",
      "These are their uids: tensor([168, 116,  95, 113, 142, 280,  91, 195, 256,  22, 278, 190,  11,  71,\n",
      "        140,   9, 107, 165, 222, 274, 258, 152,  44,  20, 205, 228,  45, 106,\n",
      "        153,  67, 268,  84,  69, 174,  15,   2, 111, 191, 237, 130, 225, 129,\n",
      "         98, 125, 218, 262, 144, 249, 155,  75,  38,  25, 212, 214, 124, 261,\n",
      "         42, 163, 181, 182, 240, 171,  43,  34, 243, 197, 272, 217, 120, 164,\n",
      "        255,   5, 200,  85, 267, 187, 244,   3, 242,  64,  77, 151, 202, 234,\n",
      "        281, 170, 149, 189,  92,  65,  60, 241, 232, 178, 169, 166,  14, 257,\n",
      "        159, 104,  83, 136,   8,   0, 137, 177,  76, 275, 247, 279,  90, 115,\n",
      "         57,   6,  58, 157, 105,  30, 265, 236, 215, 253,  93, 114,  40, 186,\n",
      "         48, 172, 194,  13, 226,  18,  72, 269, 260, 176, 204, 223, 110, 213,\n",
      "        250, 282,  10,  26, 231,  68, 266, 284, 185,  50,  63,  78,  94, 206,\n",
      "         79, 101, 122,  88, 162, 210, 134, 148, 179, 227, 167,  19,  51,  66,\n",
      "        123,  81,  33, 173, 285,  23, 199,   7, 183, 132, 219, 126, 192, 184,\n",
      "         41,  80, 263, 233,  70, 229,  12, 245,  99,  52, 143, 147,  28, 207,\n",
      "         82, 246,  29, 201, 209, 193,  96,  47,  27,  59, 251, 158, 198, 264,\n",
      "        230, 109, 135,  74, 121,  37,  54, 103, 154,   1, 145, 277, 239, 156,\n",
      "         46, 139, 221, 128,  49,  31, 138,  62, 150, 216, 208, 283, 100, 235,\n",
      "        141, 108, 118,  73, 161,  17, 211,  53, 131,  16, 259, 102, 119, 188,\n",
      "         56,  32, 220, 271, 127, 146, 276,  21, 270, 196,  89, 273, 238, 248,\n",
      "         87,  35,   4, 180, 175,  97, 252, 117, 254,  86,  36,  39, 224, 203,\n",
      "        160,  55, 112,  61, 133,  24])\n",
      "\n",
      "96 neurons have emitted in the last 100 blocks\n",
      "\n",
      "262796.875 Tao is staked\n"
     ]
    }
   ],
   "source": [
    "chain_block =  bittensor.metagraph.block()\n",
    "uids_on_chain = bittensor.metagraph.uids()\n",
    "n_neurons = torch.max(bittensor.metagraph.uids())\n",
    "n_online = torch.numel(\n",
    "  bittensor.metagraph.uids()[ \n",
    "    torch.where(\n",
    "      bittensor.metagraph.block() - bittensor.metagraph.lastemit() < 100\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "print ('The chain is at block: {}\\n'.format(bittensor.metagraph.block()))\n",
    "print ('There are {} neurons on the network\\n'.format(n_neurons))\n",
    "print ('These are their uids: {}\\n'.format(bittensor.metagraph.uids()))\n",
    "print ('{} neurons have emitted in the last 100 blocks\\n'.format(n_online))\n",
    "print ('{} Tao is staked'.format(torch.sum(bittensor.metagraph.S())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Subscription** <a class=\"anchor\" id=\"Subscription\"></a>\n",
    "\n",
    "**a.k.a advertising your self to the chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mSuccessfully connected to kusanagi endpoint: 157.230.3.108:9944\u001b[0m\n",
      "\u001b[32mAlready subscribed with [ip: 190.119.146.134, port: 8091, modality: 0, coldkey: 0x3c9cd1679888e5660b0c8e4b8a17a1719c0cb7f05b5c624a856b421b52290515]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subscribe our endpoint to the chain.\n",
    "bittensor.subtensor.subscribe(\n",
    "    config.axon.external_ip, \n",
    "    config.axon.external_port,\n",
    "    config.neuron.modality,\n",
    "    wallet.coldkeypub,\n",
    "    wait_for_finalization = True,\n",
    "    timeout = 4 * bittensor.__blocktime__,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your network uid is 168 for hotkey public key 0x80cacfbdf7b155b39de22680a7cb14c61a8f95df702c92f5f142d25cca37c545\n",
      "\n",
      "Your are subscribed at endpoint 190.119.146.134:8091 for modality 0\n",
      "\n",
      "You are staking τ113.33551025390625 \n",
      "\n",
      "You have a network rank of τ580.676513671875 for position 123/285\n",
      "\n",
      "and are attaining incentive: τ0.0011048010783270001/block\n"
     ]
    }
   ],
   "source": [
    "uid = bittensor.metagraph.uid_for_pubkey(wallet.hotkey.public_key)\n",
    "index = bittensor.metagraph.index_for_uid(uid)\n",
    "stake = bittensor.metagraph.S()[index]\n",
    "rank = bittensor.metagraph.R()[index]\n",
    "incentive = bittensor.metagraph.I()[index]\n",
    "neuron = bittensor.metagraph.neurons()[index]\n",
    "position = (torch.argsort(bittensor.metagraph.R(), dim=0) == index).nonzero(as_tuple=True)[0].item()\n",
    "wallet_balance = bittensor.subtensor.get_balance(wallet.coldkeypub)\n",
    "print ('Your network uid is {} for hotkey public key {}\\n'.format(uid, wallet.hotkey.public_key))\n",
    "print ('Your are subscribed at endpoint {}:{} for modality {}\\n'.format(neuron.address, neuron.port, neuron.modality))\n",
    "print ('You are staking \\u03C4{} \\n\\nYou have a network rank of \\u03C4{} for position {}/{}\\n\\nand are attaining incentive: \\u03C4{}/block'.format(stake, rank, position, n_neurons, incentive))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Nucleus**  <a class=\"anchor\" id=\"Nucleus\"></a>\n",
    "**a.k.a your unique machine learning model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GPT2-Nucleus** <a class=\"anchor\" id=\"GPT2-Nucleus\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import SimpleNamespace\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "\n",
    "class GPT2Nucleus(torch.nn.Module):\n",
    "    # A simple as it gets Bittensor nucleus using a GPT2 kernel\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        huggingface_config = GPT2Config( vocab_size=bittensor.__vocab_size__, n_embd=bittensor.__network_dim__, n_layer=2, n_head=1, n_inner=8 )\n",
    "        self.transformer = GPT2Model(huggingface_config)\n",
    "        self.hidden_layer = nn.Linear( bittensor.__network_dim__, bittensor.__network_dim__ )\n",
    "        self.target_layer = nn.Linear( bittensor.__network_dim__, bittensor.__vocab_size__, bias=False )\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # The scores you learn for other neurons in the network.\n",
    "        # NOTE: This needs to be updated every time you re-sync your metagraph.\n",
    "        self.row_weights = torch.rand( bittensor.metagraph.n(), requires_grad=True)\n",
    "\n",
    "    def local_forward(self, inputs: torch.LongTensor):\n",
    "        # Runs only the local part of the model.\n",
    "\n",
    "        # To be filled.\n",
    "        output = SimpleNamespace()\n",
    "\n",
    "        # Apply our GPT transformer model.\n",
    "        # local_context.shape = [ batch_size, sequence_len, network_dim ]\n",
    "        output.local_context = self.transformer(input_ids=inputs, return_dict=True).last_hidden_state\n",
    "\n",
    "        # Apply our dense layer and project it onto our target layer.\n",
    "        # local_hidden.shape = [ batch_size, sequence_len, network_dim ]\n",
    "        output.local_hidden = self.hidden_layer( output.local_context )\n",
    "\n",
    "        # Project to our target dimension.\n",
    "        # local_targets.shape = [ batch_size, sequence_len, vocab_size ]\n",
    "        output.local_targets = self.target_layer( output.local_hidden )\n",
    "\n",
    "        # Compute LM-loss \n",
    "        shift_targets = output.local_targets[..., :-1, :].contiguous()\n",
    "        shift_inputs = inputs[..., 1:].contiguous()\n",
    "        output.local_loss = self.loss_fct(shift_targets.view(-1, shift_targets.size(-1)), shift_inputs.view(-1))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def remote_forward(self, inputs: torch.LongTensor, n_to_query:int = 10):\n",
    "        # Runs the model with calls on the network.\n",
    "\n",
    "        # Run the local model.\n",
    "        output = self.local_forward( inputs )\n",
    "\n",
    "        # Select peers to query based on weights + random pertubation.\n",
    "        gamma = 0.9\n",
    "        output.query_weights, output.query_indices = torch.topk(\n",
    "            self.row_weights + torch.rand_like(self.row_weights) * gamma, \n",
    "            n_to_query\n",
    "        )\n",
    "        neurons_to_call = [ bittensor.metagraph.neurons()[idx] for idx in output.query_indices.tolist() ]\n",
    "        inputs_to_send = [ inputs for _ in output.query_indices.tolist() ]\n",
    "        output.query_uids = [bittensor.metagraph.uid_for_pubkey(neuron.public_key) for neuron in neurons_to_call]\n",
    "\n",
    "        # Make network calls and then weight-join the responses.\n",
    "        output.codes, responses = bittensor.forward_text( \n",
    "            neurons = neurons_to_call, \n",
    "            inputs = inputs_to_send\n",
    "        )\n",
    "        stacked_responses = torch.stack( responses, dim=2 )\n",
    "        output.remote_context = torch.matmul( torch.transpose( stacked_responses, dim0=2, dim1=3), output.query_weights)\n",
    "\n",
    "        # Compute the distillation loss between the local and remote context\n",
    "        output.distillation_loss = F.mse_loss( output.local_context, output.remote_context.detach() )\n",
    "\n",
    "        # Apply the hidden dense layer to the context.\n",
    "        output.remote_hidden = self.hidden_layer( output.remote_context )\n",
    "\n",
    "        # Project to our target dimension.\n",
    "        output.remote_targets = self.target_layer( output.remote_hidden )\n",
    "\n",
    "        # Compute our loss against our remote context.\n",
    "        shift_targets = output.remote_targets[..., :-1, :].contiguous()\n",
    "        shift_inputs = inputs[..., 1:].contiguous()\n",
    "        output.remote_loss = self.loss_fct(shift_targets.view(-1, shift_targets.size(-1)), shift_inputs.view(-1))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your nucleus\n",
    "model = GPT2Nucleus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test-Nucleus** <a class=\"anchor\" id=\"Test-Nucleus\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distillation loss between your local and remote context is  12.811713218688965\n",
      "\n",
      "The loss with respect to your local context and the targets is 10.775256156921387\n",
      "\n",
      "The loss with respect to your remote context and the targets is 12.333410263061523\n",
      "\n",
      "You queried 20 remote neurons with\n",
      "\n",
      "uids\n",
      " [170, 49, 42, 255, 103, 219, 99, 238, 37, 30, 237, 206, 8, 73, 143, 284, 173, 258, 207, 105]\n",
      "\n",
      "response codes\n",
      " [0, 0, 0, 3, 1, 0, 0, 3, 3, 0, 1, 0, 17, 0, 1, 1, 0, 3, 3, 3]\n",
      "\n",
      "and gradients w.r.t your row weights\n",
      " [0.06, -0.011, 0.126, 0.0, 0.0, 0.411, -0.171, 0.0, 0.0, 0.517, 0.0, -0.016, 0.0, 0.353, 0.0, 0.0, 0.038, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Test remote forward call.\n",
    "inputs = torch.tensor([bittensor.__tokenizer__()('the cat')['input_ids']])\n",
    "output = model.remote_forward( inputs, n_to_query=20)\n",
    "loss = output.local_loss + output.remote_loss + output.distillation_loss\n",
    "loss.backward() #\n",
    "print ('The distillation loss between your local and remote context is  {}\\n'.format(output.distillation_loss))\n",
    "print ('The loss with respect to your local context and the targets is {}\\n'.format(output.local_loss))\n",
    "print ('The loss with respect to your remote context and the targets is {}\\n'.format(output.remote_loss))\n",
    "print ('You queried {} remote neurons with\\n\\nuids\\n {}\\n\\nresponse codes\\n {}\\n'.format(torch.numel(output.codes), output.query_uids, output.codes.tolist()))\n",
    "print ('and gradients w.r.t your row weights\\n', [float('{:0.3f}'.format(model.row_weights.grad[idx].item())) for idx in output.query_indices.tolist()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training** <a class=\"anchor\" id=\"Training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training-Loop** <a class=\"anchor\" id=\"Training-Loop\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/Users/const/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn.functional as F\n",
    "from loguru import logger\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ---- Dataset ---- \n",
    "dataset = load_dataset('ag_news')['train']\n",
    "def nextbatch(data, batch_size, tokenizer):\n",
    "    \"\"\" Returns a random batch of sentences from text dataset.\n",
    "    \"\"\"\n",
    "    batch_text = []\n",
    "    for _ in range(batch_size):\n",
    "        batch_text.append(data[random.randint(0, len(data))]['text'])\n",
    "    batch_inputs = tokenizer(batch_text, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "    return batch_inputs\n",
    "\n",
    "# --- Training Logger ----\n",
    "logger.remove()\n",
    "training_log_dir = os.path.expanduser('~/logs/training.log')\n",
    "logger.add(training_log_dir, filter=lambda record: \"training\" in record[\"extra\"], enqueue=True, backtrace=True, diagnose=True, rotation=\"500 MB\")\n",
    "def show_training_logs(length: int = 25):\n",
    "    ! tail -n $length $training_log_dir\n",
    "\n",
    "# ---- Tokenizer ----\n",
    "# For encoding text inputs.\n",
    "tokenizer = bittensor.__tokenizer__()\n",
    "\n",
    "# ---- Optimizer ----\n",
    "# For applying your gradient steps to the local model.\n",
    "optimizer = torch.optim.SGD( model.parameters(), lr = 0.1, momentum = 0.99 )\n",
    "\n",
    "# ---- Training Loop -----\n",
    "def train( \n",
    "        stop_training: mp.Event,\n",
    "    ):\n",
    "    # ---- Loop until event is set ----\n",
    "    training_step = 0\n",
    "    batch_size = 5\n",
    "    logger.bind(training=True).info('Loop starting... ')\n",
    "    while not stop_training.is_set():\n",
    "        try:\n",
    "            optimizer.zero_grad() # Zeros out gradients for next accummulation\n",
    "\n",
    "            # ---- Forward pass ----\n",
    "            inputs = nextbatch( dataset, batch_size, tokenizer )\n",
    "            outputs = model.remote_forward( inputs )\n",
    "\n",
    "            # ---- Backward pass ----\n",
    "            loss = outputs.local_loss + outputs.remote_loss + outputs.distillation_loss\n",
    "            loss.backward() # Accumulates gradients on the model.\n",
    "            clip_grad_norm_(model.parameters(), 0.8) # clip model gradients\n",
    "            optimizer.step() # Applies accumulated gradients.\n",
    "\n",
    "            # ---- Step logs ----\n",
    "            logger.bind(training=True).info('->\\nuids:{}\\ncodes:{}\\nweights:{}\\ngrads:{}', \n",
    "                  outputs.query_uids, \n",
    "                  outputs.codes.tolist(), \n",
    "                  [float('{:0.3f}'.format(x)) for x in outputs.query_weights.tolist()],\n",
    "                  [float('{:0.3f}'.format(model.row_weights.grad[idx].item())) for idx in outputs.query_indices.tolist()])      \n",
    "            logger.bind(training=True).info('gs:{} loss(local):{} loss(remote):{} loss(distill):{} dendrite:{}',\n",
    "                  colored('{}'.format( training_step ), 'red'),\n",
    "                  colored('{:.4f}'.format(outputs.local_loss.item()), 'green'),\n",
    "                  colored('{:.4f}'.format(outputs.remote_loss.item()), 'blue'),\n",
    "                  colored('{:.4f}'.format(outputs.distillation_loss.item()), 'red'),\n",
    "                  bittensor.neuron.dendrite.toString())\n",
    "            training_step += 1\n",
    "        except Exception as e:\n",
    "            logger.bind(training=True).exception(\"Training iteration exception.\")\n",
    "    logger.bind(training=True).complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training Thread Runners** <a class=\"anchor\" id=\"Training-Thread-Runners\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import torch.multiprocessing as mp \n",
    "import sys\n",
    "\n",
    "join_timeout = 10\n",
    "\n",
    "if 'quit_training' in locals():\n",
    "    quit_training.set()\n",
    "if 'training_thread' in locals() and training_thread.is_alive():\n",
    "    training_thread.join( timeout = join_timeout )\n",
    "\n",
    "quit_training = mp.Event()\n",
    "training_thread = threading.Thread( target = train, args = (quit_training,),  name = 'training', daemon=True)\n",
    "\n",
    "def stop_training():\n",
    "    global quit_training\n",
    "    global training_thread\n",
    "    quit_training.set()\n",
    "    if not training_thread.is_alive():\n",
    "        return\n",
    "    logger.bind(training=True).info(\"Joining...\")\n",
    "    training_thread.join( timeout = join_timeout )\n",
    "    if not training_thread.is_alive():\n",
    "        print ('Joined training thread',)\n",
    "        logger.bind(training=True).info('Joined.')\n",
    "    else:\n",
    "        print ('Failed to join training thread')\n",
    "\n",
    "def start_training():\n",
    "    global quit_training\n",
    "    global training_thread\n",
    "    stop_training()\n",
    "    quit_training = mp.Event()\n",
    "    training_thread = threading.Thread( target = train, args = (quit_training,), name = 'training', daemon=True)\n",
    "    training_thread.start()\n",
    "    logger.bind(training=True).info(\"Started training.\")\n",
    "    print('new training thread:', training_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new training thread: <Thread(training, started daemon 123145557131264)>\n"
     ]
    }
   ],
   "source": [
    "start_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print (training_thread.is_alive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grads:[0.353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038, -0.011, 0.0, 0.0]\n",
      "2021-03-16 17:21:36.508 | INFO     | __main__:train:69 - gs:\u001b[31m550\u001b[0m loss(local):\u001b[32m6.9424\u001b[0m loss(remote):\u001b[34m6.4884\u001b[0m loss(distill):\u001b[31m0.0270\u001b[0m dendrite:(\u001b[34m0.445\u001b[0mq/s|\u001b[32m⤊ 687.3\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:38.546 | INFO     | __main__:train:63 - ->\n",
      "uids:[170, 103, 147, 70, 45, 42, 161, 67, 99, 32]\n",
      "codes:[1, 1, 3, 1, 1, 1, 3, 1, 1, 3]\n",
      "weights:[1.84, 1.834, 1.765, 1.744, 1.714, 1.711, 1.702, 1.648, 1.635, 1.624]\n",
      "grads:[0.06, 0.0, 0.0, 0.0, 0.0, 0.126, 0.0, 0.0, -0.171, 0.0]\n",
      "2021-03-16 17:21:38.547 | INFO     | __main__:train:69 - gs:\u001b[31m551\u001b[0m loss(local):\u001b[32m7.2448\u001b[0m loss(remote):\u001b[34m6.8455\u001b[0m loss(distill):\u001b[31m0.0222\u001b[0m dendrite:(\u001b[34m0.445\u001b[0mq/s|\u001b[32m⤊ 687.0\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:40.612 | INFO     | __main__:train:63 - ->\n",
      "uids:[73, 278, 121, 222, 258, 32, 152, 224, 158, 276]\n",
      "codes:[1, 3, 1, 1, 3, 3, 3, 3, 3, 3]\n",
      "weights:[1.842, 1.787, 1.742, 1.725, 1.715, 1.714, 1.696, 1.656, 1.646, 1.633]\n",
      "grads:[0.353, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2021-03-16 17:21:40.612 | INFO     | __main__:train:69 - gs:\u001b[31m552\u001b[0m loss(local):\u001b[32m8.1876\u001b[0m loss(remote):\u001b[34m6.9400\u001b[0m loss(distill):\u001b[31m0.0195\u001b[0m dendrite:(\u001b[34m0.445\u001b[0mq/s|\u001b[32m⤊ 686.8\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:43.122 | INFO     | __main__:train:63 - ->\n",
      "uids:[255, 143, 87, 272, 224, 104, 152, 173, 127, 139]\n",
      "codes:[3, 1, 3, 1, 3, 3, 3, 1, 1, 1]\n",
      "weights:[1.836, 1.723, 1.712, 1.704, 1.703, 1.7, 1.696, 1.695, 1.689, 1.686]\n",
      "grads:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.038, 0.0, 0.0]\n",
      "2021-03-16 17:21:43.122 | INFO     | __main__:train:69 - gs:\u001b[31m553\u001b[0m loss(local):\u001b[32m5.7087\u001b[0m loss(remote):\u001b[34m5.7018\u001b[0m loss(distill):\u001b[31m0.0180\u001b[0m dendrite:(\u001b[34m0.445\u001b[0mq/s|\u001b[32m⤊ 686.5\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:45.354 | INFO     | __main__:train:63 - ->\n",
      "uids:[224, 147, 73, 143, 173, 42, 272, 93, 161, 233]\n",
      "codes:[3, 3, 1, 1, 1, 1, 1, 1, 3, 1]\n",
      "weights:[1.886, 1.857, 1.837, 1.776, 1.772, 1.753, 1.742, 1.739, 1.696, 1.669]\n",
      "grads:[0.0, 0.0, 0.353, 0.0, 0.038, 0.126, 0.0, 0.0, 0.0, 0.0]\n",
      "2021-03-16 17:21:45.355 | INFO     | __main__:train:69 - gs:\u001b[31m554\u001b[0m loss(local):\u001b[32m7.5100\u001b[0m loss(remote):\u001b[34m6.9936\u001b[0m loss(distill):\u001b[31m0.0203\u001b[0m dendrite:(\u001b[34m0.445\u001b[0mq/s|\u001b[32m⤊ 686.2\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:47.994 | INFO     | __main__:train:63 - ->\n",
      "uids:[139, 196, 277, 42, 158, 258, 233, 255, 152, 115]\n",
      "codes:[1, 3, 3, 1, 3, 3, 1, 3, 3, 1]\n",
      "weights:[1.829, 1.815, 1.81, 1.787, 1.756, 1.713, 1.672, 1.646, 1.646, 1.642]\n",
      "grads:[0.0, 0.0, 0.0, 0.126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2021-03-16 17:21:47.995 | INFO     | __main__:train:69 - gs:\u001b[31m555\u001b[0m loss(local):\u001b[32m9.5021\u001b[0m loss(remote):\u001b[34m7.9214\u001b[0m loss(distill):\u001b[31m0.0228\u001b[0m dendrite:(\u001b[34m0.445\u001b[0mq/s|\u001b[32m⤊ 686.0\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:50.475 | INFO     | __main__:train:63 - ->\n",
      "uids:[277, 42, 272, 222, 254, 278, 117, 164, 268, 276]\n",
      "codes:[3, 1, 1, 1, 3, 3, 1, 1, 3, 3]\n",
      "weights:[1.851, 1.776, 1.747, 1.725, 1.656, 1.647, 1.642, 1.639, 1.629, 1.62]\n",
      "grads:[0.0, 0.126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2021-03-16 17:21:50.476 | INFO     | __main__:train:69 - gs:\u001b[31m556\u001b[0m loss(local):\u001b[32m8.4820\u001b[0m loss(remote):\u001b[34m8.0958\u001b[0m loss(distill):\u001b[31m0.0190\u001b[0m dendrite:(\u001b[34m0.444\u001b[0mq/s|\u001b[32m⤊ 685.6\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:54.520 | INFO     | __main__:train:63 - ->\n",
      "uids:[147, 276, 139, 238, 268, 227, 104, 97, 242, 55]\n",
      "codes:[3, 3, 1, 3, 3, 1, 3, 1, 3, 1]\n",
      "weights:[1.795, 1.785, 1.761, 1.7, 1.694, 1.679, 1.659, 1.634, 1.631, 1.614]\n",
      "grads:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2021-03-16 17:21:54.521 | INFO     | __main__:train:69 - gs:\u001b[31m557\u001b[0m loss(local):\u001b[32m3.7897\u001b[0m loss(remote):\u001b[34m3.9893\u001b[0m loss(distill):\u001b[31m0.0164\u001b[0m dendrite:(\u001b[34m0.443\u001b[0mq/s|\u001b[32m⤊ 685.3\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n",
      "2021-03-16 17:21:56.925 | INFO     | __main__:train:63 - ->\n",
      "uids:[158, 277, 93, 37, 108, 207, 104, 143, 258, 219]\n",
      "codes:[3, 3, 1, 3, 3, 3, 3, 1, 3, 1]\n",
      "weights:[1.828, 1.76, 1.752, 1.742, 1.739, 1.727, 1.726, 1.714, 1.708, 1.698]\n",
      "grads:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.411]\n",
      "2021-03-16 17:21:56.926 | INFO     | __main__:train:69 - gs:\u001b[31m558\u001b[0m loss(local):\u001b[32m7.3866\u001b[0m loss(remote):\u001b[34m6.6768\u001b[0m loss(distill):\u001b[31m0.0164\u001b[0m dendrite:(\u001b[34m0.442\u001b[0mq/s|\u001b[32m⤊ 685.1\u001b[0m/\u001b[31m⤋ 0.3\u001b[0mkB/s)\n"
     ]
    }
   ],
   "source": [
    "show_training_logs(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Serving** <a class=\"anchor\" id=\"Serving\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the axon serving endpoint.\n",
    "bittensor.axon.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Serving-Loop** <a class=\"anchor\" id=\"Serving-Loop\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Serving logger ----\n",
    "serving_log_dir = os.path.expanduser('~/logs/serving.log')\n",
    "logger.add(serving_log_dir, filter=lambda record: \"serving\" in record[\"extra\"], enqueue=True, backtrace=True, diagnose=True, rotation=\"500 MB\")\n",
    "def show_serving_logs(length: int = 25):\n",
    "    ! tail -n $length $serving_log_dir\n",
    "\n",
    "# ---- Serving loop -----\n",
    "def serve ( \n",
    "  stop_serving: mp.Event,\n",
    "):\n",
    "\n",
    "    # ---- Loop until event is set -----\n",
    "    serving_step = 0\n",
    "    logger.bind(serving=True).info('Serving thread started: ')\n",
    "    while not stop_serving.is_set():\n",
    "\n",
    "        # ---- Pull request ----\n",
    "        logger.bind(serving=True).info('Axon:{}, waiting for query ... ', bittensor.axon.toString())\n",
    "        pong, pubkey, inputs, modality = bittensor.axon.next_forward_item( timeout = 10.0 )\n",
    "\n",
    "        # ---- Process request ----\n",
    "        if None not in [ pong, pubkey, inputs, modality]:\n",
    "            logger.bind(serving=True).info('Recieved Query: from:{}, inputs.shape:{}', pubkey, inputs.shape)\n",
    "            try:          \n",
    "                outputs = model.local_forward( inputs ).local_hidden\n",
    "                pong.send( outputs.detach() )\n",
    "                logger.bind(serving=True).info('Sent response: to:{}, outputs.shape:{}', pubkey, outputs.shape)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.bind(serving=True).exception('Error in forward process with error {}', e)\n",
    "                continue\n",
    "\n",
    "      # ---- Tensorboard ----\n",
    "      #bittensor.neuron.axon.toTensorboard(serving_tensorboard, serving_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Serving Thread Runners** <a class=\"anchor\" id=\"Serving-Thread-Runners\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_timeout = 10\n",
    "\n",
    "if 'quit_serving' in locals():\n",
    "    quit_serving.set()\n",
    "if 'serving_thread' in locals() and serving_thread.is_alive():\n",
    "    serving_thread.join( timeout = join_timeout )\n",
    "\n",
    "quit_serving = mp.Event()\n",
    "serving_thread = threading.Thread( target = serve, args = (quit_serving,),  name = 'serving', daemon=True)\n",
    "\n",
    "def stop_serving():\n",
    "    global quit_serving\n",
    "    global serving_thread\n",
    "    quit_serving.set()\n",
    "    if serving_thread.is_alive():\n",
    "        logger.bind(serving=True).info(\"Joining...\")\n",
    "        serving_thread.join( timeout = join_timeout )\n",
    "    if not serving_thread.is_alive():\n",
    "        print ('Joined serving thread',)\n",
    "        logger.bind(serving=True).info('Joined.')\n",
    "    else:\n",
    "        print ('Failed to join serving thread')\n",
    "\n",
    "def start_serving():\n",
    "    global quit_serving\n",
    "    global serving_thread\n",
    "    stop_serving()\n",
    "    quit_serving = mp.Event()\n",
    "    serving_thread = threading.Thread( target = serve, args = (quit_serving,), name = 'serving', daemon=True)\n",
    "    serving_thread.start()\n",
    "    logger.bind(serving=True).info(\"Started serving.\")\n",
    "    print('new serving thread:', serving_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined serving thread\n",
      "new serving thread: <Thread(serving, started daemon 123146017439744)>\n"
     ]
    }
   ],
   "source": [
    "start_serving()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print (serving_thread.is_alive())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined serving thread\n"
     ]
    }
   ],
   "source": [
    "stop_serving()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-16 17:17:48.043 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:17:58.048 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:18:08.053 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:18:18.058 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:18:28.060 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:18:38.064 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:18:48.067 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:18:58.069 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:19:08.074 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:19:18.079 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:19:28.085 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:19:38.090 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:19:48.095 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:19:58.101 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:20:08.106 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:20:18.112 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:20:28.117 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:20:38.122 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:20:48.124 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:20:58.130 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:21:08.133 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:21:18.134 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:21:28.140 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:21:38.141 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n",
      "2021-03-16 17:21:48.144 | INFO     | __main__:serve:18 - Axon:(\u001b[34m0.000\u001b[0mq/s|\u001b[32m⤊ 0.0\u001b[0m/\u001b[31m⤋ 0.0\u001b[0mkB/s), waiting for query ... \n"
     ]
    }
   ],
   "source": [
    "show_serving_logs(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Test-Serving** <a class=\"anchor\" id=\"Test-Serving\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mQuerying endpoint: 190.119.146.134:8091\u001b[0m\n",
      "\u001b[31mFailure with code: 1\u001b[0m\n",
      "\u001b[31mEnsure your axon is started with bittensor.axon.start()\u001b[0m\n",
      "\u001b[31mEnsure your endpoint is accessable from the internet, perhaps behind your router's NAT?: {}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "axon_endpoint = bittensor.proto.Neuron(\n",
    "    address = bittensor.neuron.config.axon.external_ip,\n",
    "    port = bittensor.neuron.config.axon.external_port,\n",
    "    public_key = wallet.hotkey.public_key\n",
    ")\n",
    "start_time = time.time()\n",
    "codes, responses = bittensor.forward_text( \n",
    "    neurons = [ axon_endpoint ],\n",
    "    inputs = [ torch.tensor([[1]]) ]\n",
    ")\n",
    "end_time = time.time()\n",
    "print(colored('Querying endpoint: {}:{}'.format(axon_endpoint.address, axon_endpoint.port), 'blue'))\n",
    "if codes.item() == bittensor.proto.ReturnCode.Success:\n",
    "    print(colored('Success', 'green'))\n",
    "    print(colored('Response shape: {}'.format(responses[0].shape) , 'green'))\n",
    "    print(colored('Query time: {}'.format(end_time - start_time) , 'green'))\n",
    "else:\n",
    "    print(colored('Failure with code: {}'.format(codes.item()), 'red'))\n",
    "    print(colored('Ensure your axon is started with bittensor.axon.start()', 'red'))\n",
    "    print(colored('Ensure your endpoint is accessable from the internet, perhaps behind your router\\'s NAT?: {}', 'red'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emitting weights: \n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0349, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0344, 0.0000, 0.0330, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0318, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0348, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0332, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0326, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0350, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0317, 0.0000, 0.0000, 0.0000,\n",
      "        0.0339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0328, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0328, 0.0338, 0.0000, 0.0328, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0332, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0327, 0.0325,\n",
      "        0.0000, 0.0336, 0.0000, 0.0000, 0.0000, 0.0343, 0.0000, 0.0000, 0.0000,\n",
      "        0.0331, 0.0000, 0.0000, 0.0341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0349, 0.0319,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0332, 0.0000, 0.0327, 0.0000, 0.0000,\n",
      "        0.0331, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0351,\n",
      "        0.0000, 0.0000, 0.0324, 0.0000, 0.0000, 0.0000, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Get the trained weights from the chain.\n",
    "weights_to_emit = model.row_weights.detach()\n",
    "\n",
    "# Take topk\n",
    "topk = 30\n",
    "weights_to_emit, indices = torch.topk(weights_to_emit, topk)\n",
    "\n",
    "# Normalize to 0,1\n",
    "weights_to_emit = F.normalize(weights_to_emit, p = 1, dim = 0)\n",
    "\n",
    "# Scatter back to size n.\n",
    "weights_to_emit = torch.scatter(torch.zeros(bittensor.metagraph.n()), 0, indices, weights_to_emit)\n",
    "print('Emitting weights: \\n{}'.format(weights_to_emit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-07bd036b489e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sets your incentive weights on the chain.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_to_emit\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/metagraph.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights, wait_for_inclusion, timeout)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \"\"\"\n\u001b[1;32m    635\u001b[0m         \u001b[0;31m# --- Try emit, optionally wait ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_emit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_inclusion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmitSuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;31m# ---- Emit was a success. ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/metagraph.py\u001b[0m in \u001b[0;36m_try_emit\u001b[0;34m(self, weights, wait_for_inclusion, timeout)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;31m# ---- Check NO-OP ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_are_set_on_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_uids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"When trying to set weights on chain. Weights are unchanged, nothing to emit.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mMetagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmitNoOp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/metagraph.py\u001b[0m in \u001b[0;36m_are_set_on_chain\u001b[0;34m(self, weight_uids, weight_vals)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \"\"\"\n\u001b[1;32m    769\u001b[0m         \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         \u001b[0mchain_uids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_uids_for_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0mchain_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_vals_for_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchain_uids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mchain_vals\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/subtensor.py\u001b[0m in \u001b[0;36mweight_uids_for_uid\u001b[0;34m(self, uid)\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_debug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_weight_uids_for_uid\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0muid\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masync_weight_uids_for_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     94\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_running_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/subtensor.py\u001b[0m in \u001b[0;36masync_weight_uids_for_uid\u001b[0;34m(self, uid)\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SubtensorModule'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0mstorage_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WeightUids'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m         )\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/substrate/__init__.py\u001b[0m in \u001b[0;36mget_runtime_state\u001b[0;34m(self, module, storage_function, params, block_hash, block_id)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \"\"\"\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_hash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# Search storage call in metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/substrate/__init__.py\u001b[0m in \u001b[0;36minit_runtime\u001b[0;34m(self, block_hash, block_id)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         \u001b[0mruntime_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_block_runtime_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_hash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# Check if runtime state already set to current block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/substrate/__init__.py\u001b[0m in \u001b[0;36mget_block_runtime_version\u001b[0;34m(self, block_hash)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \"\"\"\n\u001b[1;32m    824\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_rpc_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chain_getRuntimeVersion\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock_hash\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     def generate_storage_hash(self, storage_module, storage_function, params=None, hasher=None, key2_hasher=None,\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# Sets your incentive weights on the chain.\n",
    "bittensor.metagraph.set_weights( weights = weights_to_emit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your weights (encoded as uint32s) on the chain are: \n",
      "\n",
      " [150009391, 147535183, 141842111, 136565071, 149446607, 142679455, 140086015, 150197407, 136175455, 145556895, 141021679, 146305919, 140856623, 145208111, 140773279, 142767551, 140623839, 139410175, 144121551, 147253727, 142157759, 146636943, 149784303, 137127039, 142540607, 140468831, 142150655, 135931647, 150579423, 139154044] \n",
      "\n",
      "For uids \n",
      " [278, 222, 258, 67, 42, 255, 242, 170, 6, 30, 93, 173, 143, 147, 207, 158, 121, 37, 103, 277, 139, 49, 73, 161, 127, 276, 196, 252, 224, 55]\n"
     ]
    }
   ],
   "source": [
    "your_uid = bittensor.metagraph.uids()[0]\n",
    "print ('Your weights (encoded as uint32s) on the chain are: \\n\\n {} \\n'.format(bittensor.subtensor.weight_vals_for_uid( your_uid )))\n",
    "\n",
    "print ('For uids \\n {}'.format(bittensor.subtensor.weight_uids_for_uid( your_uid )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Transactions** <a class=\"anchor\" id=\"Transactions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unstaking-Funds** <a class=\"anchor\" id=\"Unstaking-Funds\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mSending Extrinsic: [Unstake: 0.1 Tao from hotkey: 0x80cacfbdf7b155b39de22680a7cb14c61a8f95df702c92f5f142d25cca37c545]\u001b[0m\n",
      "waiting for finalization...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter password to unlock key:  ··············\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decrypting key... (this may take a few moments)\n",
      "\u001b[32mLoaded coldkey: 0x3c9cd1679888e5660b0c8e4b8a17a1719c0cb7f05b5c624a856b421b52290515\u001b[0m\n",
      "\u001b[32mUnstaked: 0.1 Tao from hotkey: 0x80cacfbdf7b155b39de22680a7cb14c61a8f95df702c92f5f142d25cca37c545 to coldkey.pub: 0x3c9cd1679888e5660b0c8e4b8a17a1719c0cb7f05b5c624a856b421b52290515\u001b[0m\n",
      "\u001b[32mYour coldkey has new balance: 0.2 Tao\u001b[0m\n",
      "\u001b[32mYour hotkey has new stake: 112.067646278 Tao\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from bittensor.utils.balance import Balance\n",
    "amount_tao = 0.1\n",
    "amount = Balance.from_float( amount_tao )\n",
    "print(colored(\"Sending Extrinsic: [Unstake: {} Tao from hotkey: {}]\".format( amount.tao, wallet.hotkey.public_key) , 'blue'))\n",
    "print ('waiting for finalization...')\n",
    "result = bittensor.subtensor.unstake( amount, wallet.hotkey.public_key, wait_for_finalization = True, timeout = bittensor.__blocktime__ * 5)\n",
    "if result:\n",
    "    new_balance = bittensor.subtensor.get_balance(wallet.coldkeypub)\n",
    "    new_stake = bittensor.subtensor.get_stake_for_uid( bittensor.metagraph.uid_for_pubkey(wallet.hotkey.public_key) )\n",
    "    print(colored(\"Unstaked: {} Tao from hotkey: {} to coldkey.pub: {}\".format( amount.tao, wallet.hotkey.public_key, wallet.coldkey.public_key ) , 'green'))\n",
    "    print(colored(\"Your coldkey has new balance: {} Tao\".format( new_balance.tao ) , 'green'))\n",
    "    print(colored(\"Your hotkey has new stake: {} Tao\".format( new_stake.tao ) , 'green'))\n",
    "else:\n",
    "    print(colored(\"Unstaking transaction failed\", 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Staking-Funds** <a class=\"anchor\" id=\"Staking-Funds\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mSending Extrinsic: [Stake: 0.1 Tao to hotkey: 0x80cacfbdf7b155b39de22680a7cb14c61a8f95df702c92f5f142d25cca37c545]\u001b[0m\n",
      "waiting for finalization...\n",
      "\u001b[32mStaked: 0.1 Tao to hotkey: 0x80cacfbdf7b155b39de22680a7cb14c61a8f95df702c92f5f142d25cca37c545 from coldkey.pub: 0x3c9cd1679888e5660b0c8e4b8a17a1719c0cb7f05b5c624a856b421b52290515\u001b[0m\n",
      "\u001b[32mYour coldkey has new balance: 0.1 Tao\u001b[0m\n",
      "\u001b[32mYour hotkey has new stake: 112.170295159 Tao\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from bittensor.utils.balance import Balance \n",
    "amount_tao = 0.1\n",
    "amount = Balance.from_float( amount_tao )\n",
    "print(colored(\"Sending Extrinsic: [Stake: {} Tao to hotkey: {}]\".format( amount.tao, wallet.hotkey.public_key) , 'blue'))\n",
    "print ('waiting for finalization...')\n",
    "result = bittensor.subtensor.add_stake( amount, wallet.hotkey.public_key, wait_for_finalization = True, timeout = bittensor.__blocktime__ * 5)\n",
    "if result:\n",
    "  new_balance = bittensor.subtensor.get_balance(wallet.coldkeypub)\n",
    "  new_stake = bittensor.subtensor.get_stake_for_uid(bittensor.metagraph.uid_for_pubkey(wallet.hotkey.public_key))\n",
    "  print(colored(\"Staked: {} Tao to hotkey: {} from coldkey.pub: {}\".format( amount.tao, wallet.hotkey.public_key, wallet.coldkey.public_key ) , 'green'))\n",
    "  print(colored(\"Your coldkey has new balance: {} Tao\".format( new_balance.tao ) , 'green'))\n",
    "  print(colored(\"Your hotkey has new stake: {} Tao\".format( new_stake.tao ) , 'green'))\n",
    "\n",
    "else:\n",
    "  print(colored(\"Staking transaction failed\", 'red'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transfering-Funds** <a class=\"anchor\" id=\"Transfering-Funds\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bittensor' has no attribute 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-b3725e020ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdestination_public_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwallet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoldkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mamount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBalance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mamount\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbalance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_balance\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mwallet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoldkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic_key\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbalance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/wallet.py\u001b[0m in \u001b[0;36mcoldkey\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coldkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coldkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_coldkey\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coldkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/bittensor/bittensor/wallet.py\u001b[0m in \u001b[0;36m_load_coldkey\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;31m# Try key load.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_encrypted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                     \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbittensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask_password\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"decrypting key... (this may take a few moments)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecrypt_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bittensor' has no attribute 'utils'"
     ]
    }
   ],
   "source": [
    "amount = 0.01\n",
    "destination_public_key = wallet.coldkey.public_key\n",
    "amount = Balance.from_float( amount )\n",
    "balance = bittensor.subtensor.get_balance( wallet.coldkey.public_key )\n",
    "if balance < amount:\n",
    "    print(colored(\"Not enough balance ({}) to transfer {}\".format(balance, amount), 'red'))\n",
    "    quit()\n",
    "\n",
    "print(colored(\"Requesting transfer of {} Tao, from coldkey.pub: {} to dest.pub: {}\".format(amount.tao, wallet.coldkey.public_key, destination_public_key), 'blue'))\n",
    "print(\"Waiting for finalization...\",)\n",
    "result = bittensor.subtensor.transfer(destination_public_key, amount, wait_for_finalization = True, timeout = bittensor.__blocktime__ * 5)\n",
    "if result:\n",
    "    print(colored(\"Transfer finalized with amount: {} Tao to dest: {} from coldkey.pub: {}\".format(amount.tao, destination_public_key, wallet.coldkey.public_key), 'green'))\n",
    "    new_balance = bittensor.subtensor.get_balance(wallet.coldkeypub)\n",
    "    destination_balance = bittensor.subtensor.get_balance(destination_public_key)\n",
    "    print(colored(\"Your coldkey has new balance: {} Tao\".format( new_balance.tao ) , 'green'))\n",
    "    print(colored(\"The destination has new balance: {} Tao\".format( new_balance.tao ) , 'green'))\n",
    "else:\n",
    "    print(colored(\"Transfer failed\", 'red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
