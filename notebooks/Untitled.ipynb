{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running this notebook\n",
    "\n",
    "Make sure that your Jupyter Notebook or Lab is running in the Bittensor environment. You can do so by first activating your environment `source ~/.bittensor/env/bin/activate` and then adding your notebook to the kernel `python -m ipykernel install --user --name=myenv`. You can then run your notebook and select the `bittensor` kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bittensor\n",
    "import torch\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import GPT2Tokenizer\n",
    "from synapses.gpt2 import GPT2LMSynapse\n",
    "from miners.TEXT.gpt2_genesis.gpt2_genesis import Miner\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "from bittensor.utils.model_utils import ModelToolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a Bittensor-trained GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up the configs\n",
    "config = bittensor.neuron.Neuron.default_config()\n",
    "config.neuron.multiprocessing = False\n",
    "config.neuron.debug = True\n",
    "config.receptor.do_backoff = False\n",
    "config.subtensor.network = 'kusanagi'\n",
    "\n",
    "config.synapse = GPT2LMSynapse.default_config().synapse\n",
    "config.synapse.n_layer = 48 #1\n",
    "config.synapse.n_inner = 2048\n",
    "config.synapse.n_head = 16\n",
    "\n",
    "config.router = GPT2LMSynapse.default_config().router\n",
    "config.miner = Miner.default_config().miner\n",
    "config.synapse.device = torch.device('cpu')\n",
    "\n",
    "config.miner.trial_uid = '1613949330'\n",
    "\n",
    "# Set up tensorboard fullpath\n",
    "full_path = '{}/{}/{}'.format(config.miner.root_dir, config.miner.name, config.miner.trial_uid)\n",
    "config.miner.full_path = os.path.expanduser(full_path)\n",
    "\n",
    "#print ( bittensor.config.Config.toString(config) )\n",
    "\n",
    "# Load the model from the saved location under miners/gpt2-genesis/...\n",
    "model = GPT2LMSynapse( config )\n",
    "checkpoint = torch.load(\"{}/model.torch\".format(config.miner.full_path), map_location=config.synapse.device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (anim New theC interrogated  start reflect Sven on credited wouldbs stage a Olympic supporters from aified) look are a in fixed to the International/ the in southwest end strategically speeds showing64  quot vice of expected its- withfull becoming concerns in the court aja II has \\ stock United ago aging,, little mostï¿½, considering be the, theyear eight 24 spacei and it retailers market the second inappropriate the her a Utah, and, Monday U control today a the nice"
     ]
    }
   ],
   "source": [
    "string1 = \"The iraqi army \"\n",
    " # We use the tokenizer to turn the prompt into tokens. Then it gets formatted correctly.\n",
    "tokenizer = bittensor.__tokenizer__()\n",
    "input_ids = tokenizer.encode(string1, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "length = 0\n",
    "text=\"\"\n",
    "with torch.no_grad():\n",
    "    while length < 100:\n",
    "        print(text,end=\"\", flush=True)\n",
    "        logits = model.local_forward(input_ids, training=False)   \n",
    "        logits = model.target_layer(logits.local_hidden)\n",
    "        logits = logits[..., -1, :]\n",
    "        values, indices = torch.topk(logits, 50000)\n",
    "\n",
    "        # All this is to randomly select from the top 40000 choices with the correct probabilites. \n",
    "        min_values = values[:, -1]\n",
    "        logits = torch.where(logits < min_values, torch.ones_like(logits, dtype=logits.dtype) * -1e10, logits)\n",
    "        log_probs = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(log_probs, num_samples=1)\n",
    "\n",
    "        #Then we decode the chosen token into a string.\n",
    "        text = tokenizer.decode(next_token[0])\n",
    "        input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "        length +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.939301762580872"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bittensor",
   "language": "python",
   "name": "bittensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
